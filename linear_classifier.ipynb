{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data gen\n",
    "X = np.random.normal(0, 1, (1_000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our seperator (y = mx + b)\n",
    "m, b = 2, -1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do target classes\n",
    "class_bool = X[:, 1] < m*X[:, 0] + b + np.random.normal(0, 0.5, (1000,))\n",
    "y = -1.*class_bool + 1.*np.logical_not(class_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "plt.scatter(X[class_bool, 0], X[class_bool, 1])\n",
    "plt.scatter(X[np.logical_not(class_bool), 0], X[np.logical_not(class_bool), 1])\n",
    "plt.plot(np.arange(-3, 3, 0.1), np.arange(-3, 3, 0.1)*m + b, linewidth=2, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m = torch.nn.Parameter(torch.from_numpy(np.array([0.])), requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.from_numpy(np.array([0.])), requires_grad=True)\n",
    "    \n",
    "    def forward_train(self, X):\n",
    "        probs = torch.softmax(\n",
    "            torch.stack([X[:, 0] * self.m + self.b, X[:, 1]], dim=1),\n",
    "            dim=1\n",
    "        )\n",
    "        return -1.*probs[:,0] + 1.*probs[:,1]\n",
    "\n",
    "    def forward_test(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(X)\n",
    "        class_bool = X[:, 1] < X[:, 0] * self.m + self.b\n",
    "        return -1.*class_bool + 1.*torch.logical_not(class_bool)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.m}, {self.b}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyRepeatDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._iter_X = iter(cycle(self.X))\n",
    "        self._iter_y = iter(cycle(self.y))\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self._iter_X), next(self._iter_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LinearClassifier()\n",
    "optim = torch.optim.SGD(lc.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.SoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NumpyRepeatDataset(X, y)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 20,\n",
    ")\n",
    "iter_train_dataloader = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 1_000\n",
    "loss_steps = [i for i in range(total_steps//10, total_steps+1, total_steps//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 1_000\n",
    "loss_steps = set([i for i in range(total_steps//10, total_steps+1, total_steps//10)])\n",
    "viz_steps = set([1, 10, 50, 100, 200])\n",
    "\n",
    "for i in range(total_steps):\n",
    "    optim.zero_grad()\n",
    "    t_X, t_y = next(iter_train_dataloader)\n",
    "    output = lc.forward_train(t_X)\n",
    "    loss = loss_fn(output, t_y)\n",
    "    \n",
    "    if i in loss_steps:\n",
    "        print(f\"loss @ {i}th step: {loss}\")\n",
    "    if i in viz_steps:\n",
    "        plt.scatter(X[class_bool, 0], X[class_bool, 1])\n",
    "        plt.scatter(X[np.logical_not(class_bool), 0], X[np.logical_not(class_bool), 1])\n",
    "        plt.plot(\n",
    "            np.arange(-3, 3, 0.1), \n",
    "            np.arange(-3, 3, 0.1)*lc.m.detach().cpu().numpy() + lc.b.detach().cpu().numpy(), \n",
    "            linewidth=2, color=\"red\"\n",
    "        )\n",
    "        plt.gca().set_title(f\"{i}th step\")\n",
    "        plt.show()\n",
    "    \n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y,\n",
    "    lc.forward_test(X).numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "plt.scatter(X[class_bool, 0], X[class_bool, 1])\n",
    "plt.scatter(X[np.logical_not(class_bool), 0], X[np.logical_not(class_bool), 1])\n",
    "plt.plot(\n",
    "    np.arange(-3, 3, 0.1), \n",
    "    np.arange(-3, 3, 0.1)*lc.m.detach().cpu().numpy() + lc.b.detach().cpu().numpy(), \n",
    "    linewidth=2, color=\"red\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610d70144db798de2d4bb5dcee849625d95221a0a4889cdbe27ccad9556d3744"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
